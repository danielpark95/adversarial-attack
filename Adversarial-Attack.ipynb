{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"Simple, end-to-end, LeNet-5-like convolutional MNIST model example.\n",
    "\n",
    "This should achieve a test error of 0.7%. Please keep this model as simple and\n",
    "linear as possible, it is meant as a tutorial for simple convolutional models.\n",
    "Run with --self_test on the command line to execute a short self-test.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy \n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# CVDF mirror of http://yann.lecun.com/exdb/mnist/\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cvdf-datasets/mnist/'\n",
    "WORK_DIRECTORY = 'data'\n",
    "IMAGE_SIZE = 28\n",
    "NUM_CHANNELS = 1\n",
    "PIXEL_DEPTH = 255\n",
    "NUM_LABELS = 10\n",
    "VALIDATION_SIZE = 5000  # Size of the validation set.\n",
    "SEED = 66478  # Set to None for random seed.\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100  # Number of steps between evaluations.\n",
    "\n",
    "\n",
    "def data_type():\n",
    "  \"\"\"Return the type of the activations, weights, and placeholder variables.\"\"\"\n",
    "  return tf.float32\n",
    "\n",
    "\n",
    "def maybe_download(filename):\n",
    "  \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n",
    "  if not tf.gfile.Exists(WORK_DIRECTORY):\n",
    "    tf.gfile.MakeDirs(WORK_DIRECTORY)\n",
    "  filepath = os.path.join(WORK_DIRECTORY, filename)\n",
    "  if not tf.gfile.Exists(filepath):\n",
    "    filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n",
    "    with tf.gfile.GFile(filepath) as f:\n",
    "      size = f.size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "\n",
    "\n",
    "def extract_data(filename, num_images):\n",
    "  \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "\n",
    "  Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "  \"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(16)\n",
    "    buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "    data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "  \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "  print('Extracting', filename)\n",
    "  with gzip.open(filename) as bytestream:\n",
    "    bytestream.read(8)\n",
    "    buf = bytestream.read(1 * num_images)\n",
    "    labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "  return labels\n",
    "\n",
    "def error_rate(predictions, labels):\n",
    "  \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n",
    "  return 100.0 - (\n",
    "      100.0 *\n",
    "      numpy.sum(numpy.argmax(predictions, 1) == labels) /\n",
    "      predictions.shape[0])\n",
    "\n",
    "# Get the data.\n",
    "train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n",
    "train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n",
    "test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n",
    "test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "# Extract it into numpy arrays.\n",
    "train_data = extract_data(train_data_filename, 6000)\n",
    "train_labels = extract_labels(train_labels_filename, 6000)\n",
    "test_data = extract_data(test_data_filename, 1000)\n",
    "test_labels = extract_labels(test_labels_filename, 1000)\n",
    "\n",
    "# Generate a validation set.\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]\n",
    "train_data = train_data[VALIDATION_SIZE:, ...]\n",
    "train_labels = train_labels[VALIDATION_SIZE:]\n",
    "num_epochs = NUM_EPOCHS\n",
    "train_size = train_labels.shape[0]\n",
    "\n",
    "# This is where training samples and labels are fed to the graph.\n",
    "# These placeholder nodes will be fed a batch of training data at each\n",
    "# training step using the {feed_dict} argument to the Run() call below.\n",
    "train_data_node = tf.placeholder(\n",
    "    data_type(),\n",
    "    shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "train_labels_node = tf.placeholder(tf.int64, shape=(BATCH_SIZE,))\n",
    "eval_data = tf.placeholder(\n",
    "    data_type(),\n",
    "    shape=(EVAL_BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "\n",
    "# The variables below hold all the trainable weights. They are passed an\n",
    "# initial value which will be assigned when we call:\n",
    "# {tf.global_variables_initializer().run()}\n",
    "conv1_weights = tf.Variable(\n",
    "  tf.truncated_normal([5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED, dtype=data_type()))\n",
    "conv1_biases = tf.Variable(tf.zeros([32], dtype=data_type()))\n",
    "conv2_weights = tf.Variable(tf.truncated_normal(\n",
    "  [5, 5, 32, 64], stddev=0.1,\n",
    "  seed=SEED, dtype=data_type()))\n",
    "conv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=data_type()))\n",
    "fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "  tf.truncated_normal([IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "                      stddev=0.1,\n",
    "                      seed=SEED,\n",
    "                      dtype=data_type()))\n",
    "fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=data_type()))\n",
    "fc2_weights = tf.Variable(tf.truncated_normal([512, NUM_LABELS],\n",
    "                                            stddev=0.1,\n",
    "                                            seed=SEED,\n",
    "                                            dtype=data_type()))\n",
    "fc2_biases = tf.Variable(tf.constant(\n",
    "  0.1, shape=[NUM_LABELS], dtype=data_type()))\n",
    "\n",
    "# We will replicate the model structure for the training subgraph, as well\n",
    "# as the evaluation subgraphs, while sharing the trainable parameters.\n",
    "def model(data, train=False):\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    conv = tf.nn.conv2d(data,\n",
    "                        conv1_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    conv = tf.nn.conv2d(pool,\n",
    "                        conv2_weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding='SAME')\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(relu,\n",
    "                          ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1],\n",
    "                          padding='SAME')\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool,\n",
    "        [pool_shape[0], pool_shape[1] * pool_shape[2] * pool_shape[3]])\n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "      hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases\n",
    "\n",
    "# Training computation: logits + cross-entropy loss.\n",
    "logits = model(train_data_node, True)\n",
    "loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "  labels=train_labels_node, logits=logits))\n",
    "\n",
    "# L2 regularization for the fully connected parameters.\n",
    "regularizers = (tf.nn.l2_loss(fc1_weights) + tf.nn.l2_loss(fc1_biases) +\n",
    "              tf.nn.l2_loss(fc2_weights) + tf.nn.l2_loss(fc2_biases))\n",
    "# Add the regularization term to the loss.\n",
    "loss += 5e-4 * regularizers\n",
    "\n",
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=data_type())\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  0.01,                # Base learning rate.\n",
    "  batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "  train_size,          # Decay step.\n",
    "  0.95,                # Decay rate.\n",
    "  staircase=True)\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                     0.9).minimize(loss,\n",
    "                                                   global_step=batch)\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "eval_prediction = tf.nn.softmax(model(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "############################## BEGIN ADDED CODE ###############################\n",
    "\n",
    "# Extension of the MNIST model to support single image input/output.\n",
    "single_image = tf.placeholder(data_type(),\n",
    "                              shape=(1, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS))\n",
    "single_prediction = tf.nn.softmax(model(single_image))\n",
    "\n",
    "# Parameters and variables for generating adversarial images.\n",
    "x = tf.placeholder(tf.float32, (1,28,28,1), name='x')        # Input\n",
    "c = tf.placeholder(tf.float32, (), name='c')                 # Hyperparameter\n",
    "target = tf.placeholder(tf.int32, (), name='target')         # Target class\n",
    "delta = tf.get_variable('delta',[1,28,28,1],tf.float32, \n",
    "                        initializer = tf.initializers.zeros) # Distortion   \n",
    "\n",
    "# Box constraint to ensure all pixels are within the range (-0.5, 0.5)\n",
    "x_scaled = x + 0.5                                      # Rescale to (0,1) \n",
    "w = tf.atanh(x_scaled)                                  # w_i = arctanh(x_i)\n",
    "adv_image = tf.tanh(w + delta) - 0.5                    # Transform and rescale\n",
    "adv_logits = model(adv_image)                           # Logits from model\n",
    "\n",
    "# Loss Function as formulated on page 9 of Carlini & Wagner.\n",
    "# minimize ||x'-x||_2^2 + c * f(x'), where\n",
    "# f(x') = max(max{Z(x')_i : i!= t} - Z(x')_t, -k)\n",
    "distance_loss = tf.reduce_mean(tf.square(adv_image - x)) # ||x'-x||_2^2\n",
    "inner = tf.reduce_max(adv_logits)                        # max{Z(x')_i : i!= t}\n",
    "outer = tf.reduce_max(adv_logits -                       # Z(x')_t\n",
    "                   tf.one_hot(\n",
    "                       tf.fill([1],target),\n",
    "                       10,\n",
    "                       on_value=0.0,\n",
    "                       off_value=float('inf')))\n",
    "misclassify_loss = tf.nn.relu(inner - outer)       # f(x')\n",
    "adv_loss = distance_loss + c * misclassify_loss          # Final loss function\n",
    "\n",
    "# Optimizer\n",
    "adv_optimizer = tf.train.AdamOptimizer(learning_rate = 1e-2)\n",
    "adv_train_op = adv_optimizer.minimize(adv_loss, var_list=[delta])\n",
    "\n",
    "#image = [test_data[1]] # size = (1, 28, 28, 1)\n",
    "\n",
    "############################## END ADDED CODE #################################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized!\n",
      "Step 0 (epoch 0.00), 3.0 ms\n",
      "Minibatch loss: 8.334, learning rate: 0.010000\n",
      "Minibatch error: 85.9%\n",
      "Validation error: 84.6%\n",
      "Step 100 (epoch 6.40), 81.9 ms\n",
      "Minibatch loss: 3.228, learning rate: 0.007351\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 8.6%\n",
      "Test error: 7.8%\n"
     ]
    }
   ],
   "source": [
    "# Small utility function to evaluate a dataset by feeding batches of data to\n",
    "# {eval_data} and pulling the results from {eval_predictions}.\n",
    "# Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "      raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "      end = begin + EVAL_BATCH_SIZE\n",
    "      if end <= size:\n",
    "        predictions[begin:end, :] = sess.run(\n",
    "            eval_prediction,\n",
    "            feed_dict={eval_data: data[begin:end, ...]})\n",
    "      else:\n",
    "        batch_predictions = sess.run(\n",
    "            eval_prediction,\n",
    "            feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\n",
    "        predictions[begin:, :] = batch_predictions[begin - size:, :]\n",
    "    return predictions\n",
    "\n",
    "# Create a local session to run the training.\n",
    "export_dir = '/tmp/final_model'\n",
    "saver = tf.train.Saver()\n",
    "start_time = time.time()\n",
    "with tf.Session() as sess:\n",
    "    # Run all the initializers to prepare the trainable parameters.\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('Initialized!')\n",
    "    # Loop through training steps.\n",
    "    for step in xrange(int(num_epochs * train_size) // BATCH_SIZE):\n",
    "      # Compute the offset of the current minibatch in the data.\n",
    "      # Note that we could use better randomization across epochs.\n",
    "      offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "      batch_data = train_data[offset:(offset + BATCH_SIZE), ...]\n",
    "      batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "      # This dictionary maps the batch data (as a numpy array) to the\n",
    "      # node in the graph it should be fed to.\n",
    "      feed_dict = {train_data_node: batch_data,\n",
    "                   train_labels_node: batch_labels}\n",
    "      # Run the optimizer to update weights.\n",
    "      sess.run(optimizer, feed_dict=feed_dict)\n",
    "      # print some extra information once reach the evaluation frequency\n",
    "      if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        l, lr, predictions = sess.run([loss, learning_rate, train_prediction],\n",
    "                                      feed_dict=feed_dict)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        print('Step %d (epoch %.2f), %.1f ms' %\n",
    "              (step, float(step) * BATCH_SIZE / train_size,\n",
    "               1000 * elapsed_time / EVAL_FREQUENCY))\n",
    "        print('Minibatch loss: %.3f, learning rate: %.6f' % (l, lr))\n",
    "        print('Minibatch error: %.1f%%' % error_rate(predictions, batch_labels))\n",
    "        print('Validation error: %.1f%%' % error_rate(\n",
    "            eval_in_batches(validation_data, sess), validation_labels))\n",
    "        sys.stdout.flush()\n",
    "    # Finally print the result!\n",
    "    test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "    print('Test error: %.1f%%' % test_error)\n",
    "    saver.save(sess, export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "############################## BEGIN ADDED CODE ###############################\n",
    "\n",
    "# Find indices of images that are labeled 2\n",
    "def find_twos_indices(test_labels):\n",
    "    indices = []\n",
    "    for i in range(len(test_labels)):\n",
    "        if test_labels[i] == 2 and (i not in [2,6,7,9]):\n",
    "            indices.append(i)\n",
    "        if len(indices) == 10:\n",
    "            break\n",
    "    return indices\n",
    "indices = find_twos_indices(test_labels)\n",
    "\n",
    "# Plot 10x3 grid according to spec\n",
    "def plot(orig_images, orig_preds, adv_images, adv_preds):\n",
    "    %matplotlib inline    \n",
    "    fig = plt.figure(figsize=(5, 12))\n",
    "    gs = gridspec.GridSpec(11,3,wspace=0.1,hspace=0.1)\n",
    "    for i in range(10):\n",
    "        # Original Image\n",
    "        ax = fig.add_subplot(gs[i,0])\n",
    "        ax.imshow(numpy.squeeze(orig_images[i]), cmap='gray')\n",
    "        ax.set_xlabel('2 ({0:.1%})'.format(numpy.max(orig_preds[i])), fontsize=12)\n",
    "        if i == 0:\n",
    "            ax.set_title('Original',fontsize=18)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # Delta\n",
    "        ax = fig.add_subplot(gs[i,1])\n",
    "        img = ax.imshow(numpy.squeeze(adv_images[i]-orig_images[i]), cmap='gray')\n",
    "        if i == 0:\n",
    "            ax.set_title('Delta',fontsize=18)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "        # Adversarial Image\n",
    "        ax = fig.add_subplot(gs[i,2])\n",
    "        img = ax.imshow(numpy.squeeze(adv_images[i]), cmap='gray')\n",
    "        if i == 0:\n",
    "            ax.set_title('Adversarial',fontsize=18)\n",
    "        ax.set_xlabel('6 ({0:.1%})'.format(numpy.max(adv_preds[i])), fontsize=12)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    gs.tight_layout(fig)\n",
    "    os.makedirs('img', exist_ok=True)\n",
    "    plt.savefig('img/adversarial_attack.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/final_model\n"
     ]
    }
   ],
   "source": [
    "# Start session to find delta\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, export_dir)\n",
    "    twos = test_data[indices]\n",
    "    orig_images, orig_preds = [], []\n",
    "    adv_images, adv_preds = [], []\n",
    "    \n",
    "    for image in twos:\n",
    "        image = [image]\n",
    "        feed_dict = {\n",
    "            x: image,            # Input image\n",
    "            c: 0.005,            # Hyperparameter\n",
    "            target: 6            # Reclassify\n",
    "        }\n",
    "        \n",
    "        # train model to find best xadv according to loss \n",
    "        for i in range(10000):\n",
    "            sess.run(adv_train_op, feed_dict = feed_dict)\n",
    "        \n",
    "        # Original image and prediction\n",
    "        orig_image = image\n",
    "        orig_images.append(orig_image)\n",
    "        orig_pred = sess.run(single_prediction,\n",
    "                             feed_dict = {single_image: orig_image})\n",
    "        orig_preds.append(orig_pred)\n",
    "        \n",
    "        # Adversarial image and prediction\n",
    "        adv_image1 = sess.run(adv_image, feed_dict=feed_dict)\n",
    "        adv_images.append(adv_image1)\n",
    "        adv_pred = sess.run(single_prediction,\n",
    "                            feed_dict = {single_image: adv_image1})\n",
    "        adv_preds.append(adv_pred)\n",
    "    \n",
    "    plot(orig_images, orig_preds, adv_images, adv_preds)\n",
    "\n",
    "############################## END ADDED CODE #################################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
